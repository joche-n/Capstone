{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e68a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd58bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdd521f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 54 30\n"
     ]
    }
   ],
   "source": [
    "# Create YOLO format label\n",
    "# YOLO format: <class> <x_center> <y_center> <width> <height>\n",
    "# Values are normalized to [0, 1]\n",
    "# {\"file_name\": \"0001.png\", \"objects\": {\"bbox\": [[302.0, 109.0, 73.0, 52.0]], \"categories\": [0]}}\n",
    "BBOXS_SIZE = 70\n",
    "trust = 2\n",
    "\n",
    "\n",
    "val_split = 0.1\n",
    "test_split = 0.15\n",
    "\n",
    "copy_files = True\n",
    "\n",
    "detections = {\n",
    "    \"images\": [],  # list of all images in the dataset\n",
    "    \"annotations\": [],  # list of all annotations in the dataset\n",
    "    \"categories\": []  # list of all categories\n",
    "}\n",
    "count_labl = 0\n",
    "\n",
    "meta_train = []\n",
    "meta_test = []\n",
    "meta_val = []\n",
    "\n",
    "\n",
    "source = []\n",
    "destination = []\n",
    "\n",
    "\n",
    "def splittung(data, val_split=0.1, test_split=0.15):\n",
    "    # test split\n",
    "    size_det = len(data)\n",
    "\n",
    "    test_split_len = int(size_det*test_split)\n",
    "\n",
    "    test_tomos = np.random.choice(\n",
    "        data, replace=False, size=test_split_len)\n",
    "\n",
    "    train_tomos = []\n",
    "    tomo=()\n",
    "    [train_tomos.append(tomo) for tomo in data if tomo not in test_tomos]\n",
    "\n",
    "    # Validation split\n",
    "    size_train = len(train_tomos)\n",
    "    val_split_len = int(size_train*val_split)\n",
    "\n",
    "    val_tomos = np.random.choice(\n",
    "        train_tomos, replace=False, size=val_split_len)\n",
    "    train_tomos_new = []\n",
    "    tomo=()\n",
    "    [train_tomos_new.append(tomo)for tomo in train_tomos if tomo not in val_tomos]\n",
    "    train_tomos = train_tomos_new\n",
    "\n",
    "    return train_tomos, test_tomos, val_tomos\n",
    "\n",
    "\n",
    "def transform_labels_to_coco(labels, trust):\n",
    "\n",
    "    detections = {\n",
    "        \"images\": [],  # list of all images in the dataset\n",
    "        \"annotations\": [],  # list of all annotations in the dataset\n",
    "        \"categories\": []  # list of all categories\n",
    "    }\n",
    "\n",
    "    detec_count = 0\n",
    "    img_id_list = []\n",
    "\n",
    "    for label in labels:\n",
    "\n",
    "        z=label[2]\n",
    "\n",
    "        for b in np.arange(int(z)-trust, int(z)+trust+1):\n",
    "            if b < 0:\n",
    "                continue\n",
    "            width = float(BBOXS_SIZE)\n",
    "            height = float(BBOXS_SIZE)\n",
    "            x_center=label[4]\n",
    "            y_center=label[3]\n",
    "\n",
    "            if BBOXS_SIZE/2 > x_center or BBOXS_SIZE/2 > (label[-3]-x_center):\n",
    "                width = float((x_center-1)/2)\n",
    "            if BBOXS_SIZE/2 > y_center or BBOXS_SIZE/2 > (label[-4]-y_center):\n",
    "                height = float((y_center-1)/2)\n",
    "\n",
    "            x_top_left=int(x_center-width/2)\n",
    "            y_top_left=int(y_center-height/2)\n",
    "\n",
    "            img_id = int(f\"{int(label[1].split('_')[1],16)}{b:04d}\")\n",
    "            img_name = f\"{label[1]}_slice_{b:04d}.jpg\"\n",
    "\n",
    "            if img_id not in img_id_list:\n",
    "                img_id_list.append(img_name)\n",
    "                detections[\"images\"].append({\"id\": img_id,\n",
    "                                             \"width\": label[-3],\n",
    "                                             \"height\": label[-4],\n",
    "                                             \"file_name\": img_name\n",
    "                                             })\n",
    "\n",
    "            detections[\"annotations\"].append({\"id\": detec_count,\n",
    "                                              \"image_id\": img_id,  # the id of the image that the annotation belongs to\n",
    "                                              \"category_id\": 0,  # the id of the category that the annotation belongs to\n",
    "                                              \"area\": float(width*height),\n",
    "                                              \"bbox\": [x_top_left, y_top_left, width, height],\n",
    "                                              \"iscrowd\": 0\n",
    "                                              })\n",
    "            \n",
    "            detec_count += 1\n",
    "\n",
    "    detec_count = 0\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "def get_coco_meta_file(detections, tomo_splits, coco_dir_path, source_path, copy_files=False):\n",
    "    meta_val = {\n",
    "    \"images\": [],  \n",
    "    \"annotations\": [],  \n",
    "    \"categories\": [{\"id\": 0, \"name\": \"Motor\",\"supercategory\": None}]  \n",
    "    }\n",
    "\n",
    "    meta_train = {\n",
    "    \"images\": [],  \n",
    "    \"annotations\": [],  \n",
    "    \"categories\": [{\"id\": 0, \"name\": \"Motor\",\"supercategory\": None}]  \n",
    "    }\n",
    "\n",
    "    meta_test = {\n",
    "    \"images\": [],  \n",
    "    \"annotations\": [],  \n",
    "    \"categories\": [{\"id\": 0, \"name\": \"Motor\",\"supercategory\": None}]  \n",
    "    }\n",
    "\n",
    "\n",
    "    train_split, test_split, val_split = tomo_splits\n",
    "    train_id = [int(i.split('_')[1], 16) for i in train_split]\n",
    "    test_id = [int(i.split('_')[1], 16) for i in test_split]\n",
    "    val_id = [int(i.split('_')[1], 16) for i in val_split]\n",
    "\n",
    "\n",
    "\n",
    "    for image in detections[\"images\"]:\n",
    "        \n",
    "        tomo_name=f\"{image['file_name'].split('_')[0]}_{image['file_name'].split('_')[1]}\"\n",
    "\n",
    "        if tomo_name in train_split:\n",
    "            split_list=image[\"file_name\"].split(\"_\")\n",
    "            destination = coco_dir_path+\"train/\"+image[\"file_name\"]\n",
    "            source = source_path+f\"{split_list[0]}_{split_list[1]}/{split_list[2]}_{split_list[-1]}\"\n",
    "\n",
    "            if not os.path.isdir(os.path.dirname(destination)):\n",
    "                os.mkdir(os.path.dirname(destination))\n",
    "            shutil.copyfile(source, destination)\n",
    "\n",
    "            meta_train[\"images\"].append(image)\n",
    "\n",
    "        if tomo_name in test_split:\n",
    "            meta_test[\"images\"].append(image)\n",
    "            split_list=image[\"file_name\"].split(\"_\")\n",
    "            destination = coco_dir_path+\"test/\"+image[\"file_name\"]\n",
    "            source = source_path+f\"{split_list[0]}_{split_list[1]}/{split_list[2]}_{split_list[-1]}\"\n",
    "\n",
    "            if not os.path.isdir(os.path.dirname(destination)):\n",
    "                os.mkdir(os.path.dirname(destination))\n",
    "            shutil.copyfile(source, destination)\n",
    "\n",
    "            meta_test[\"images\"].append(image)\n",
    "\n",
    "        if tomo_name in val_split:\n",
    "            split_list=image[\"file_name\"].split(\"_\")\n",
    "            destination = coco_dir_path+\"valid/\"+image[\"file_name\"]\n",
    "            source = source_path+f\"{split_list[0]}_{split_list[1]}/{split_list[2]}_{split_list[-1]}\"\n",
    "\n",
    "            if not os.path.isdir(os.path.dirname(destination)):\n",
    "                os.mkdir(os.path.dirname(destination))\n",
    "            shutil.copyfile(source, destination)\n",
    "            \n",
    "            meta_val[\"images\"].append(image)\n",
    "\n",
    "    for label in detections[\"annotations\"]:\n",
    "        if int(str(label[\"image_id\"])[:-4]) in train_id:\n",
    "            meta_train[\"annotations\"].append(label)\n",
    "        elif int(str(label[\"image_id\"])[:-4]) in test_id:\n",
    "            meta_test[\"annotations\"].append(label)\n",
    "        elif int(str(label[\"image_id\"])[:-4]) in val_id:\n",
    "            meta_val[\"annotations\"].append(label)\n",
    "\n",
    "\n",
    "    meta_path=\"coco/\"\n",
    "    with open(meta_path+\"train/_annotations.coco.json\", 'w') as json_output:\n",
    "        json.dump(meta_train, json_output)\n",
    "        json_output.write('\\n')\n",
    "\n",
    "    with open(meta_path+\"test/_annotations.coco.json\", 'w') as json_output:\n",
    "        json.dump(meta_test, json_output)\n",
    "        json_output.write('\\n')\n",
    "\n",
    "\n",
    "    with open(meta_path+\"valid/_annotations.coco.json\", 'w') as json_output:\n",
    "        json.dump(meta_val, json_output)\n",
    "        json_output.write('\\n')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df=pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "    # to list\n",
    "    labels= df[df[\"Motor axis 0\"]!=-1].values\n",
    "    len(labels)\n",
    "\n",
    "    tomot_with_motor_list = df[df[\"Number of motors\"] > 0][\"tomo_id\"].unique()\n",
    "\n",
    "    data = splittung(tomot_with_motor_list)\n",
    "    print(len(data[0]),len(data[1]),len(data[2]))\n",
    "    detections = transform_labels_to_coco(labels, trust)\n",
    "\n",
    "    dest_path = \"coco/\"\n",
    "    source_path = \"train/\"\n",
    "\n",
    "    get_coco_meta_file(detections, data, dest_path, source_path, copy_files=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03891bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_slice(slice_data):\n",
    "    \"\"\"\n",
    "    Normalize slice data using 2nd and 98th percentiles\n",
    "    \"\"\"\n",
    "    # Calculate percentiles\n",
    "    p2 = np.percentile(slice_data, 2)\n",
    "    p98 = np.percentile(slice_data, 98)\n",
    "    \n",
    "    # Clip the data to the percentile range\n",
    "    clipped_data = np.clip(slice_data, p2, p98)\n",
    "    \n",
    "    # Normalize to [0, 255] range\n",
    "    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n",
    "    \n",
    "    return np.uint8(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6296b82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32442/2396500507.py:41: UserWarning: Argument(s) 'std_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(std_limit=(0.1, 0.2), p=0.5),\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_pipeline = A.Compose(\n",
    "    [\n",
    "    A.SquareSymmetry(p=1),\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
    "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.7),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=0.8),\n",
    "    ], p=0.7),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
    "        A.MedianBlur(blur_limit=5, p=0.5),\n",
    "        A.MotionBlur(blur_limit=(3, 7), p=0.5),\n",
    "    ], p=0.5),\n",
    "        \n",
    "    A.OneOf([\n",
    "        A.GaussNoise(std_limit=(0.1, 0.2), p=0.5),\n",
    "        A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.5),\n",
    "        A.MultiplicativeNoise(multiplier=(0.9, 1.1), per_channel=True, p=0.5),\n",
    "        A.SaltAndPepper(p=0.5)\n",
    "    ], p=0.5)\n",
    "    # Add bbox_params or keypoint_params if dealing with bounding boxes or keypoints\n",
    "    ],   \n",
    "    #bbox_params=A.BboxParams(format='coco', label_fields=[])\n",
    ")\n",
    "\n",
    "#Remember to visualize the output!\n",
    "\n",
    "img_list_dir=os.listdir(\"coco/train\")\n",
    "\n",
    "for p, img in enumerate(img_list_dir):\n",
    "\n",
    "    if img[0]!=\"_\":\n",
    "        image = cv.imread(\"coco/train/\"+img)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        orignal_norm=normalize_slice(image)\n",
    "        augmented=train_pipeline(image=image)\n",
    "        augmented_norm=normalize_slice(augmented[\"image\"])\n",
    "        cv.imwrite(f\"coco/train/aug/{p:04d}\"+img,augmented_norm)\n",
    "        cv.imwrite(f\"coco/train/aug/\"+img,augmented_norm)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
